{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pre-Processing\n",
    "\n",
    "This notebook contains my version of image data pre-processing. The dataset I used to train the model is [FUNSD Dataset](https://guillaumejaume.github.io/FUNSD/dataset.zip). I downloaded the dataset, and save it to my local directory. \n",
    "\n",
    "The main goal of this notebook is to create a directory containing the bad version of my training dataset, and actually labeling it with the good version image (original image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing things\n",
    "import os\n",
    "import time\n",
    "import traceback\n",
    "import numpy\n",
    "from numpy import asarray\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some parameters:\n",
    "\n",
    "| Parameter Name | Description |\n",
    "|---|---|\n",
    "| `SCALE` | Resizing scale factor |\n",
    "| `INPUT_DIM` | Input and Output patch sizes |\n",
    "| `PAD` | Padding that need to be added to output patches |\n",
    "| `STRIDE` | Larger STRIDE will result in higher pixel skipping. Which will reduce more image quality. On the dzlab's github, `STRIDE` explained as *\"the stride which is the number of pixels we'll slide both in the horizontal and vertical axes to extract patches\"* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = 2.0\n",
    "INPUT_DIM = 33\n",
    "LABEL_SIZE = 21\n",
    "PAD = int((INPUT_DIM - LABEL_SIZE) / 2.0)\n",
    "STRIDE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Making support functions\n",
    "This part is making support function to actually reducing the image quality for the testing data. \n",
    "\n",
    "List functions to be made:\n",
    "\n",
    "1. `resize_image` \n",
    "As its name suggests, this function will resize the image by the specified factor. \n",
    "\n",
    "If you want to downsample the image, you can set the factor by 1 / x or x / 100.\n",
    "If you want to upsample the image, you can set the factor by x\n",
    "\n",
    "2. convert_image_to_array\n",
    "As its name suggests, this function will convert a raw image data to a numpy array. You may notice that this function is only contains 1 line, but trust me, as a skilled-issue user (me), you may want to do this for better understanding of the function.\n",
    "\n",
    "3. downsize_upsize_image\n",
    "This function will downsample, and then upsample the image. It says, if this happen, for some reason the image will be start degraded on its quality.\n",
    "\n",
    "4. tight_crop_image\n",
    "This function will \n",
    "\n",
    "5. crop_input\n",
    "This function will slice through the input image to the destinated dimension.\n",
    "\n",
    "6. crop_output\n",
    "This function will slice through the target image to the destinated dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_image\n",
    "def resize_image(image_array, factor):\n",
    "    original_image = Image.fromarray(image_array)\n",
    "\n",
    "    new_size = numpy.array(original_image.size) * factor\n",
    "    new_size = new_size.astype(numpy.int32)\n",
    "    new_size = tuple(new_size)\n",
    "\n",
    "    resized = original_image.resize(new_size)\n",
    "    resized = img_to_array(resized)\n",
    "    resized = resized.astype(numpy.uint8)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "\n",
    "# convert image to array\n",
    "# This function will convert an image to numpy array spatial data.\n",
    "# @param\n",
    "#  - str image_path\n",
    "# \n",
    "# @return \n",
    "#  - numpy array\n",
    "def convert_image_to_array(image_path):\n",
    "    return asarray(Image.open(image_path))\n",
    "\n",
    "def downsize_upsize_image(image, scale):\n",
    "    scaled = resize_image(image, 1.0 / scale)\n",
    "    scaled = resize_image(scaled, scale) # In the reference, the scale is divided by 1.0. What changes over it?\n",
    "\n",
    "    return scaled\n",
    "\n",
    "def tight_crop_image(image, scale):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    width -= int(width % scale)\n",
    "    height -= int(height % scale)\n",
    "\n",
    "    return image[:height, :width]\n",
    "\n",
    "def crop_input(image, x, y):\n",
    "    x_slice = slice(x, x + INPUT_DIM)\n",
    "    y_slice = slice(y, y + INPUT_DIM)\n",
    "    return image[y_slice, x_slice]\n",
    "\n",
    "def crop_output(image, x, y):\n",
    "    x_slice = slice(x + PAD, x + PAD + LABEL_SIZE)\n",
    "    y_slice = slice(y + PAD, y + PAD + LABEL_SIZE)\n",
    "    \n",
    "    return image[y_slice, x_slice]\n",
    "\n",
    "def write_log(log, type, session):\n",
    "    # [2023-10-01T00:00][INFO] Some message\n",
    "    # Put in ../../logs\n",
    "    # File name is current time session with format of [Notebook - Session Ymd H:i]\n",
    "    operation = \"x\";\n",
    "    log_path = \"../../logs/\" + \"Notebook - Session \"+session + \".log\";\n",
    "\n",
    "    if(Path(log_path).is_file()):\n",
    "        operation = \"a\"\n",
    "\n",
    "    fopen = open(log_path, operation);\n",
    "    fopen.write(\"[\" + time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"]\" + \"[\"+type+\"]\" + log + \"\\n\");\n",
    "    fopen.close();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Making the bad and the good image version.\n",
    "Since the code from dzlab mainly uses Google Collab, and unfortunately I'm using Windows, I have to kind of change how the code is interacting with the image entirely.\n",
    "\n",
    "This algorithm below explains my methodology:\n",
    "\n",
    "1. Set the directory using Path from pathlib\n",
    "2. For every file within the directory:\n",
    "    > 1. Pre-Process the image using keras img_to_array\n",
    "    > 2. Save the original image array file to disk.\n",
    "    > 3. Making LowRes images from the normal quality image.\n",
    "    > 4. Saving the LowRes images to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm;\n",
    "\n",
    "def load_image():\n",
    "    directory = Path(\"E:\\\\New folder\\\\TrainTest\")\n",
    "    current_session = time.strftime(\"%Y%m%d %H%M\");\n",
    "\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        # Generate target filename\n",
    "        file_name = datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_\" + file + \".numpy\"\n",
    "        \n",
    "        try:\n",
    "            full_path = os.path.join(directory, file)\n",
    "\n",
    "            # Call out 2.1\n",
    "            image = img_to_array(load_img(full_path))\n",
    "            image = image.astype(numpy.uint8)\n",
    "            \n",
    "            # Call out 2.2\n",
    "            numpy.save(\"../resources/np_image_original/original_\" + file_name, image)\n",
    "\n",
    "            # Call out 2.3\n",
    "\n",
    "            image = tight_crop_image(image, SCALE)\n",
    "            scaled = downsize_upsize_image(image, SCALE)\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            for y in range(0, height - INPUT_DIM + 1, STRIDE):\n",
    "                for x in range(0, width - INPUT_DIM + 1, STRIDE):\n",
    "                    crop = crop_input(scaled, x, y)\n",
    "                    target = crop_output(image, x, y)\n",
    "\n",
    "                    numpy.save(\"../resources/np_image_input/input_\" + file_name + '.np', crop)\n",
    "                    numpy.save(\"../resources/np_image_output/target_\" + file_name + '.np', target)\n",
    "\n",
    "            write_log(\"Successfully writing numpy array from \" + file_name, \"INFO\", current_session)\n",
    "        except Exception as e:\n",
    "            write_log(\"Skipping writing numpy array from \" + file_name + \": \" + traceback.format_exc(), \"ERROR\", current_session)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [2:00:58<00:00,  3.63s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Execute the load_image command\n",
    "load_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_super_resolution_p3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
