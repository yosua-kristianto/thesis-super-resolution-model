{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pre-Processing\n",
    "\n",
    "This notebook contains my version of image data pre-processing. The dataset I used to train the model is [FUNSD Dataset](https://guillaumejaume.github.io/FUNSD/dataset.zip). I downloaded the dataset, and save it to my local directory. \n",
    "\n",
    "The main goal of this notebook is to create a directory containing the bad version of my training dataset, and actually labeling it with the good version image (original image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing things\n",
    "import os\n",
    "import time\n",
    "import traceback\n",
    "import numpy\n",
    "from numpy import asarray\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some parameters:\n",
    "\n",
    "| Parameter Name | Description |\n",
    "|---|---|\n",
    "| `SCALE` | Resizing scale factor |\n",
    "| `INPUT_DIM` | Input and Output patch sizes |\n",
    "| `PAD` | Padding that need to be added to output patches |\n",
    "| `STRIDE` | Larger STRIDE will result in higher pixel skipping. Which will reduce more image quality. On the dzlab's github, `STRIDE` explained as *\"the stride which is the number of pixels we'll slide both in the horizontal and vertical axes to extract patches\"* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = 2.0\n",
    "INPUT_DIM = 33\n",
    "LABEL_SIZE = 21\n",
    "PAD = int((INPUT_DIM - LABEL_SIZE) / 2.0)\n",
    "STRIDE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Making support functions\n",
    "This part is making support function to actually reducing the image quality for the testing data. \n",
    "\n",
    "List functions to be made:\n",
    "\n",
    "1. `resize_image` \n",
    "As its name suggests, this function will resize the image by the specified factor. \n",
    "\n",
    "If you want to downsample the image, you can set the factor by 1 / x or x / 100.\n",
    "If you want to upsample the image, you can set the factor by x\n",
    "\n",
    "2. convert_image_to_array\n",
    "As its name suggests, this function will convert a raw image data to a numpy array. You may notice that this function is only contains 1 line, but trust me, as a skilled-issue user (me), you may want to do this for better understanding of the function.\n",
    "\n",
    "3. downsize_upsize_image\n",
    "This function will downsample, and then upsample the image. It says, if this happen, for some reason the image will be start degraded on its quality.\n",
    "\n",
    "4. tight_crop_image\n",
    "This function will \n",
    "\n",
    "5. crop_input\n",
    "This function will slice through the input image to the destinated dimension.\n",
    "\n",
    "6. crop_output\n",
    "This function will slice through the target image to the destinated dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize_image\n",
    "def resize_image(image_array, factor):\n",
    "    original_image = Image.fromarray(image_array)\n",
    "\n",
    "    new_size = numpy.array(original_image.size) * factor\n",
    "    new_size = new_size.astype(numpy.int32)\n",
    "    new_size = tuple(new_size)\n",
    "\n",
    "    resized = original_image.resize(new_size)\n",
    "    resized = img_to_array(resized)\n",
    "    resized = resized.astype(numpy.uint8)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "\n",
    "# convert image to array\n",
    "# This function will convert an image to numpy array spatial data.\n",
    "# @param\n",
    "#  - str image_path\n",
    "# \n",
    "# @return \n",
    "#  - numpy array\n",
    "def convert_image_to_array(image_path):\n",
    "    return asarray(Image.open(image_path))\n",
    "\n",
    "def downsize_upsize_image(image, scale):\n",
    "    scaled = resize_image(image, 1.0 / scale)\n",
    "    scaled = resize_image(scaled, scale) # In the reference, the scale is divided by 1.0. What changes over it?\n",
    "\n",
    "    return scaled\n",
    "\n",
    "def tight_crop_image(image, scale):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    width -= int(width % scale)\n",
    "    height -= int(height % scale)\n",
    "\n",
    "    return image[:height, :width]\n",
    "\n",
    "def crop_input(image, x, y):\n",
    "    x_slice = slice(x, x + INPUT_DIM)\n",
    "    y_slice = slice(y, y + INPUT_DIM)\n",
    "    return image[y_slice, x_slice]\n",
    "\n",
    "def crop_output(image, x, y):\n",
    "    x_slice = slice(x + PAD, x + PAD + LABEL_SIZE)\n",
    "    y_slice = slice(y + PAD, y + PAD + LABEL_SIZE)\n",
    "    \n",
    "    return image[y_slice, x_slice]\n",
    "\n",
    "def write_log(log, type, session):\n",
    "    # [2023-10-01T00:00][INFO] Some message\n",
    "    # Put in ../../logs\n",
    "    # File name is current time session with format of [Notebook - Session Ymd H:i]\n",
    "    operation = \"x\";\n",
    "    log_path = \"../../logs/\" + \"Notebook - Session \"+session + \".log\";\n",
    "\n",
    "    if(Path(log_path).is_file()):\n",
    "        operation = \"a\"\n",
    "\n",
    "    fopen = open(log_path, operation);\n",
    "    fopen.write(\"[\" + time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"]\" + \"[\"+type+\"]\" + log + \"\\n\");\n",
    "    fopen.close();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Making the bad and the good image version.\n",
    "Since the code from dzlab mainly uses Google Collab, and unfortunately I'm using Windows, I have to kind of change how the code is interacting with the image entirely.\n",
    "\n",
    "This algorithm below explains my methodology:\n",
    "\n",
    "1. Set the directory using Path from pathlib\n",
    "2. For every file within the directory:\n",
    "    > 1. Pre-Process the image using keras img_to_array\n",
    "    > 2. Save the original image array file to disk.\n",
    "    > 3. Making LowRes images from the normal quality image.\n",
    "    > 4. Saving the LowRes images to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm;\n",
    "\n",
    "def load_image():\n",
    "    directory = Path(\"E:\\\\New folder\\\\TrainTest\")\n",
    "    current_session = time.strftime(\"%Y%m%d %H%M\");\n",
    "\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        # Generate target filename\n",
    "        file_name = datetime.now().strftime(\"%Y%m%d%H%M%S\") + \"_\" + file + \".numpy\"\n",
    "        \n",
    "        try:\n",
    "            full_path = os.path.join(directory, file)\n",
    "\n",
    "            # Call out 2.1\n",
    "            image = img_to_array(load_img(full_path))\n",
    "            image = image.astype(numpy.uint8)\n",
    "            \n",
    "            # Call out 2.2\n",
    "            # numpy.save(\"../resources/np_image_original/original_\" + file_name, image)\n",
    "\n",
    "            # Call out 2.3\n",
    "\n",
    "            image = tight_crop_image(image, SCALE)\n",
    "            scaled = downsize_upsize_image(image, SCALE)\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            for y in range(0, height - INPUT_DIM + 1, STRIDE):\n",
    "                for x in range(0, width - INPUT_DIM + 1, STRIDE):\n",
    "                    crop = crop_input(scaled, x, y)\n",
    "                    target = crop_output(image, x, y)\n",
    "\n",
    "                    numpy.save(\"../resources/np_image_input/input_\" + \"_{\"+ str(x) +\"}_\" + \"_{\"+ str(y) +\"}_\" + file_name + '.np', crop)\n",
    "                    numpy.save(\"../resources/np_image_output/target_\" + \"_{\"+ str(x) +\"}_\" + \"_{\"+ str(y) +\"}_\" + file_name + '.np', target)\n",
    "\n",
    "            write_log(\n",
    "                    \"Successfully writing numpy array from \" + file_name,\n",
    "                    \"INFO\", \n",
    "                    current_session\n",
    "            )\n",
    "        except Exception as e:\n",
    "            write_log(\"Skipping writing numpy array from \" + file_name + \": \" + traceback.format_exc(), \"ERROR\", current_session)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 230/2000 [34:29<4:25:25,  9.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Code Repository\\Campus\\Thesis\\Pre Processing\\thesis-super-resolution-model\\model-training\\notebook\\1.data_preprocessing.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Execute the load_image command\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m load_image()\n",
      "\u001b[1;32me:\\Code Repository\\Campus\\Thesis\\Pre Processing\\thesis-super-resolution-model\\model-training\\notebook\\1.data_preprocessing.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             target \u001b[39m=\u001b[39m crop_output(image, x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m             numpy\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m../resources/np_image_input/input_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x) \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(y) \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.np\u001b[39m\u001b[39m'\u001b[39m, crop)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m             numpy\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39m../resources/np_image_output/target_\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(x) \u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m}_\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(y) \u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m}_\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m file_name \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.np\u001b[39;49m\u001b[39m'\u001b[39;49m, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     write_log(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSuccessfully writing numpy array from \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m             current_session\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Code%20Repository/Campus/Thesis/Pre%20Processing/thesis-super-resolution-model/model-training/notebook/1.data_preprocessing.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\thesis_super_resolution_p3_10\\lib\\site-packages\\numpy\\lib\\npyio.py:546\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[0;32m    545\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 546\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    547\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[1;32mc:\\anaconda3\\envs\\thesis_super_resolution_p3_10\\lib\\site-packages\\numpy\\lib\\format.py:730\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m--> 730\u001b[0m         array\u001b[39m.\u001b[39;49mtofile(fp)\n\u001b[0;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m numpy\u001b[39m.\u001b[39mnditer(\n\u001b[0;32m    733\u001b[0m                 array, flags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mexternal_loop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbuffered\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mzerosize_ok\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    734\u001b[0m                 buffersize\u001b[39m=\u001b[39mbuffersize, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Execute the load_image command\n",
    "load_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_super_resolution_p3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
