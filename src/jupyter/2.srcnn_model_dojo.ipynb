{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Dojo\n",
    "\n",
    "In short, this notebook dedicated for SRCNN models training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import os\n",
    "import tensorflow\n",
    "import numpy\n",
    "from glob import glob\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import ReLU, Conv2D, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Taking Data to be ready \n",
    "\n",
    "Currently I'm only have a low amount of training data set. Hence I will only make sure the code is working properly right now and saving the actual training process later. So, I will kind of using all the datasets to be trained of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation():\n",
    "    input = [*glob(\"../resources/np_image_input/*\")]\n",
    "    output = [*glob(\"../resources/np_image_output/*\")]\n",
    "\n",
    "    print(len(input), len(output))\n",
    "    input.sort()\n",
    "    output.sort()\n",
    "\n",
    "    return input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchesDataset(tensorflow.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, *args, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        self.input = [*glob('../resources/np_image_input/*')]\n",
    "        self.output = [*glob('../resources/np_image_output/*')]\n",
    "        self.input.sort()\n",
    "        self.output.sort()\n",
    "        self.total_data = len(self.input)\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of batches\n",
    "        return int(self.total_data / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns one batch\n",
    "        indices = self.random_indices()\n",
    "        input = numpy.array([numpy.load(self.input[idx]) for idx in indices])\n",
    "        output = numpy.array([numpy.load(self.output[idx]) for idx in indices])\n",
    "        return input, output\n",
    "\n",
    "    def random_indices(self):\n",
    "        return numpy.random.choice(list(range(self.total_data)), self.batch_size, p=numpy.ones(self.total_data)/self.total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Definition\n",
    "\n",
    "I can't explain why is this like this... Unfortunately...\n",
    "\n",
    "in short, this step will create a model, create an optimization through it, and create model summary\n",
    "\n",
    "Dzlab said *\"The architecture of the SRCNN model is very simple, it has only convolutional layers, one to downsize the input and extract image features and a later one to upside to generate the output image. The following helper function is used to create an instance of the model.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(height, width, depth):\n",
    "    input = Input(shape=(height, width, depth))\n",
    "    x = Conv2D(filters=64, kernel_size=(9, 9), kernel_initializer='he_normal')(input)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(1, 1), kernel_initializer='he_normal')(x)\n",
    "    x = ReLU()(x)\n",
    "    output = Conv2D(filters=depth, kernel_size=(5, 5), kernel_initializer='he_normal')(x)\n",
    "    return Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "INPUT_DIM = 33 # This came from the 1.data_processing.ipynb\n",
    "optimizer = Adam(learning_rate = 1e-3, decay = 1e-3 / EPOCHS)\n",
    "model = create_model(INPUT_DIM, INPUT_DIM, 3)\n",
    "model.compile(loss = 'mse', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 33, 33, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 25, 25, 64)        15616     \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 25, 25, 32)        2080      \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 25, 25, 32)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 21, 21, 3)         2403      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,099\n",
      "Trainable params: 20,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# See model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Plot the model\n",
    "tensorflow.keras.utils.plot_model(model, show_shapes = True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weight\n",
    "checkpoint_path = \"training/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fitting the Model\n",
    "Let's fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# model.fit(data_preparation(), epochs=EPOCHS, callbacks=[cp_callback])\n",
    "\n",
    "train_dataset = PatchesDataset(1024)\n",
    "print(len(train_dataset))\n",
    "# model.fit(train_dataset, epochs=EPOCHS, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Save the model to be deployed on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../resources/suhu/shifu.mdl'\n",
    "# model.save(path)\n",
    "# new_model = tf.keras.models.load_model(path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ad69851df0cb4453262857d3b1a61ab8eb1167f128089e34c7816a6b823fb9b"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
